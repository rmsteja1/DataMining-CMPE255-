{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFqIMlX0hG73"
   },
   "source": [
    "# HW 1 Part 1: Preprocessing the Credit Approval Dataset\n",
    "\n",
    "Perform the following tasks on the credit approval dataset (crx.data contains the dataset and crx.names contains the description of the dataset). Complete all the LP questions to receive a \"low pass\" grade on the homework. Complete all the questions (both LP and HP) to receive a \"high pass\" grade on the homework. \n",
    "\n",
    "Note that if you are unable to complete any of the LP questions satisfactorily, you will receive a grade of \"revision required\". You can revise and resubmit your work in exchange for a token. Please review the syllabus for more information on specifications grading.\n",
    "\n",
    "**VERY IMPORTANT**: Include **ALL** the references you used for this assignment, including names of classmates you discuss with. Failure to cite your sources counts as an act of academic dishonesty and will be taken seriously without zero tolerance. You will automatically receive a “fail” grade in the homework and further serious penalties may be imposed.\n",
    "\n",
    "NOTE: You can look for help on the Internet but refrain from referencing too much. Please cite all your sources in your submission. \n",
    "When you submit your assignment, you automatically agree to the following statement. If you do not agree, it is your responsibility to provide the reason.\n",
    "\n",
    "“*I affirm that I have neither given nor received unauthorized help in completing this homework. I am not aware of others receiving such help. I have cited all the sources in the solution file.*”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WZyc-1p4Dc-y"
   },
   "outputs": [],
   "source": [
    "## Your code goes here. Import the csv into a pandas dataframe here\n",
    "import pandas as pd\n",
    "\n",
    "data_frame=pd.read_csv(\"crx.data\",header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6ElwLnzjL0a"
   },
   "source": [
    "[LP 1] Deal with the missing values in the credit analysis dataset. Explain what you did with the following columns:\n",
    "\n",
    "1. Column A1 (at index 0) \n",
    "2. Column A2 (at index 1)\n",
    "3. Column A4 (at index 3)\n",
    "4. Column A5 (at index 4)\n",
    "5. Column A6 (at index 5)\n",
    "6. Column A7 (at index 6)\n",
    "7. Column A14 (at index 13)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DMY-ZEKcDfC7"
   },
   "outputs": [],
   "source": [
    "## Your code for LP 1 goes here. \n",
    "\n",
    "#For columnA1(Index0):\n",
    "data_frame[0]=data_frame[0].replace(\"?\",data_frame[0].mode()[0]) #Replacing '?' with mode value 'b'\n",
    "\n",
    "#For columnA2(Index1):\n",
    "data_frame[1]=data_frame[1].replace(\"?\",\"0\")\n",
    "data_frame[1]=data_frame[1].astype('float64') #Cahnging data type to float\n",
    "data_frame[1]=data_frame[1].replace(0.0,data_frame[1].mean())# Replacing 0's with the mean value\n",
    "\n",
    "#For columnA4(Index3):\n",
    "data_frame[3]=data_frame[3].replace(\"?\",data_frame[3].mode()[0]) #Replacing '?' with mode value 'u'\n",
    "\n",
    "#For Column A5 (at index 4):\n",
    "data_frame[4]=data_frame[4].replace(\"?\",data_frame[4].mode()[0]) #Replacing '?' with mode value 'g'\n",
    "\n",
    "#For Column A6 (at index 5):\n",
    "data_frame[5]=data_frame[5].replace(\"?\",data_frame[5].mode()[0]) #Replacing '?' with mode value 'c'\n",
    "\n",
    "#For column A7(index 6):\n",
    "data_frame[6]=data_frame[6].replace(\"?\",data_frame[6].mode()[0]) #Replacing '?' with mode value 'V'\n",
    "\n",
    "#For column A14(index 13):\n",
    "\"\"\"\n",
    "OLD COMMANDS\n",
    "\n",
    "data_frame[13]=data_frame[13].replace(\"?\",\"00000\") #Replacing '?' with '00000' for converting them to 0 in future\n",
    "data_frame[13]=data_frame[13].replace(\"00000\",'0') #Replacing '00000' with 0\n",
    "data_frame[13]=data_frame[13].astype('int64') # Converting to int64 data type\"\"\"\n",
    "\n",
    "\n",
    "#Corrected Commands:\n",
    "#As the data in this column looks like and identifiers, rows with no identifier can be removed\n",
    "#Flling them with mean,median or mode will corrupt the relation of the data\n",
    "data_frame[13]=data_frame[13].replace(\"?\",\"00000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh9UM5hqn1HO"
   },
   "source": [
    "\n",
    "[LP 2] Use encoders and convert the categorical variables to numerical values: Columns A1, A4, A5, A6, A7, A9, A10, A12, A13\n",
    "\n",
    "[HP 1] Describe your choice of encoder for these columns and explain why they are appropriate for the column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-T1QCICvDiDz"
   },
   "outputs": [],
   "source": [
    "## Your code for LP 2 goes here. \n",
    "\n",
    "#For column A1:\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder1 = LabelBinarizer()\n",
    "encoded_Purchased = encoder1.fit_transform(data_frame[0].values.reshape(-1,1))\n",
    "data_frame[15]=encoded_Purchased\n",
    "\n",
    "\n",
    "#For column A4:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder2 = LabelEncoder()\n",
    "data_frame[16] = encoder2.fit_transform(data_frame[3])\n",
    "\n",
    "#For column A5:\n",
    "data_frame[17] = encoder2.fit_transform(data_frame[4])\n",
    "\n",
    "#For column A6:\n",
    "data_frame[18] = encoder2.fit_transform(data_frame[5])\n",
    "\n",
    "\n",
    "#For column A7:\n",
    "data_frame[19] = encoder2.fit_transform(data_frame[6])\n",
    "\n",
    "#For column A9:\n",
    "data_frame[20]= encoder1.fit_transform(data_frame[8].values.reshape(-1,1))\n",
    "\n",
    "#For column A10:\n",
    "data_frame[21]=encoder1.fit_transform(data_frame[9].values.reshape(-1,1))\n",
    "\n",
    "#For column A12:\n",
    "data_frame[22]=encoder1.fit_transform(data_frame[11].values.reshape(-1,1))\n",
    "\n",
    "#For column A13:\n",
    "data_frame[23] = encoder2.fit_transform(data_frame[12])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qK5itr7pDnCJ"
   },
   "source": [
    "< Your answer for HP 1 goes here >\n",
    "\n",
    "#For column A1:\n",
    "Enoder Used:LabelBinarizer\n",
    "Reason : In the given column there are only two unique values 'a','b' so they can be converted into 1(for b) and 0(for a). After conversion their logic and meaning is not disturbed.\n",
    "\n",
    "#For column A4:\n",
    "Encoder Used : LabelEncode\n",
    "\n",
    "Reason: In the given column there are only three different values \"u\",\"y\",\"l\", if we can generate 3 different values which can represent these three characters we can ensure that the relation in the column is not broken. By using LabelEnoder we gave 1 for 'u',2 for 'y' and 0 for 'l'.\n",
    "\n",
    "\n",
    "#For column A5:\n",
    "Encoder Used : LabelEncode\n",
    "\n",
    "Reason: In the given column there are only three different values \"g\",\"p\",\"gg\", if we can generate 3 different values which can represent these three characters we can ensure that the relation in the column is not broken. By using LabelEnoder we gave 1 for 'gg',2 for 'p' and 0 for 'g'.\n",
    "\n",
    "#For column A6:\n",
    "Encoder Used : LabelEncode\n",
    "Reason: In this column there are 14 different string values for each of these value unique numeric value is assigned. Due to this we have generated unique numeric values without breaking the realtion.\n",
    "\n",
    "\n",
    "#For column A7:\n",
    "Encoder Used : LabelEncode\n",
    "Reason: In this column there are 9 different string values for each of these value unique numeric value is assigned. Due to this we have generated unique numeric values without breaking the realtion.\n",
    "\n",
    "#For column A9:\n",
    "Enoder Used:LabelBinarizer\n",
    "Reason : In the given column there are only two unique values 't','f' so they can be converted into 1(for t) and 0(for f). After conversion their logic and meaning is not disturbed.\n",
    "\n",
    "\n",
    "#For column A10:\n",
    "Enoder Used:LabelBinarizer\n",
    "Reason : In the given column there are only two unique values 't','f' so they can be converted into 1(for t) and 0(for f). After conversion their logic and meaning is not disturbed.\n",
    "\n",
    "#For column A11:\n",
    "Enoder Used:LabelBinarizer\n",
    "Reason : In the given column there are only two unique values 't','f' so they can be converted into 1(for t) and 0(for f). After conversion their logic and meaning is not disturbed.\n",
    "\n",
    "#For column A12:\n",
    "Enoder Used:LabelBinarizer\n",
    "Reason : In the given column there are only two unique values 't','f' so they can be converted into 1(for t) and 0(for f). After conversion their logic and meaning is not disturbed.\n",
    "\n",
    "#For column A13:\n",
    "Encoder Used : LabelEncode\n",
    "Reason: In this column there are 3 different string values for each of these value unique numeric value is assigned. Due to this we have generated unique numeric values without breaking the realtion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYIkt1kNn4AQ"
   },
   "source": [
    "[LP 3] Use an appropriate scaler to scale the numerical values to a suitable range of values. Briefly explain the process you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uY1xpzTmDpBr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReason:\\ni) Used MinMaxScaler from Sklean library\\nii) In the second line of the code I have defined the scale range which is 1 to5.\\nii) Later, I have changed range of the numeric columns between 1to 5\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code for LP 3 goes here.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler(feature_range=(1, 5))\n",
    "data_frame[[1,2,7,10,13,14,15,16,17,18,19,20,21,22,23]]=min_max.fit_transform(data_frame[[1,2,7,10,13,14,15,16,17,18,19,20,21,22,23]])\n",
    "\n",
    "\"\"\"\n",
    "Reason:\n",
    "i) Used MinMaxScaler from Sklean library\n",
    "ii) In the second line of the code I have defined the scale range which is 1 to5.\n",
    "ii) Later, I have changed range of the numeric columns between 1to 5\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWT5NohBoJjV"
   },
   "source": [
    "Save your clean dataset in a file called **crx_clean.data**. Submit this file along with the ipynb solution file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "49nC0392n5cG"
   },
   "outputs": [],
   "source": [
    "## Your code to save the dataframe to a csv file goes here.\n",
    "data_frame.to_csv(\"crx_clean.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQYb_dd3obyT"
   },
   "source": [
    "# References\n",
    "Include ALL your references here. \n",
    "https://michael-fuchs-python.netlify.app/2019/06/16/types-of-encoder/\n",
    "https://www.geeksforgeeks.org/python-scaling-numbers-column-by-column-with-pandas/\n",
    "\n",
    "Note: I had few discussions with one of my class mate Sai Varshit Talluri [015952586]\n",
    "\n",
    "# What to turn in:\n",
    "1. The ipynb solution file, which includes the references\n",
    "2. If you use Colab or GitHub for version control, please share a link to your notebook or GitHub repository\n",
    "3. The crx_clean.data file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW1 Part 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
