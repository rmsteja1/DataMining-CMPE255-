{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFqIMlX0hG73"
   },
   "source": [
    "# HW 1 Part 2: Preprocessing Bank Marketing Dataset\n",
    "\n",
    "The original dataset is available here: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "We have a modified subset of this dataset to practice data  preprocessing. \n",
    "\n",
    "Perform the following tasks on the provided bank marketing dataset (bank-hw1.csv contains the dataset and bank-names.txt contains the description of the original dataset). Complete all the LP questions to receive a \"low pass\" grade on the homework. Complete all the questions (both LP and HP) to receive a \"high pass\" grade on the homework. \n",
    "\n",
    "Note that if you are unable to complete any of the LP questions satisfactorily, you will receive a grade of \"revision required\". You can revise and resubmit your work in exchange for a token. Please review the syllabus for more information on specifications grading.\n",
    "\n",
    "**VERY IMPORTANT**: Include **ALL** the references you used for this assignment, including names of classmates you discuss with. Failure to cite your sources counts as an act of academic dishonesty and will be taken seriously without zero tolerance. You will automatically receive a “fail” grade in the homework and further serious penalties may be imposed.\n",
    "\n",
    "NOTE: You can look for help on the Internet but refrain from referencing too much. Please cite all your sources in your submission. \n",
    "When you submit your assignment, you automatically agree to the following statement. If you do not agree, it is your responsibility to provide the reason.\n",
    "\n",
    "“*I affirm that I have neither given nor received unauthorized help in completing this homework. I am not aware of others receiving such help. I have cited all the sources in the solution file.*”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "t1jTtAbpCOMM"
   },
   "outputs": [],
   "source": [
    "## Your code goes here. Import the csv into a pandas dataframe here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_frame=pd.read_csv(\"bank-hw1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6ElwLnzjL0a"
   },
   "source": [
    "[LP 1] Deal with the erroneous and missing values in the dataset. Below is necessary information about the columns that contain missing and erroneous values:\n",
    "\n",
    "1. Age: must be in the range 18-100 \n",
    "2. Job: case insensitive field, column contains clerical errors where extra dots or punctuations are left in the entries \n",
    "3. Marital: marital status is case insensitive; short forms of the entries refer to the same value (e.g., div is the same as divorced); there are typographical errors in the entries\n",
    "4. Day and month: some entries have both these values combined in one column \n",
    "5. Duration: all entries must be non-negative\n",
    "\n",
    "The set of possible values in each column and their meaning is provided in the bank-names.txt file. You can use the information to make decisions. Please explain your choices even if you only took a guess. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code for LP 1 goes here. \n",
    "\n",
    "#For Age column:\n",
    "data_frame['age'].loc[(data_frame['age']<18)]=18\n",
    "data_frame['age'].loc[(data_frame['age']>100)]=100\n",
    "\n",
    "# For Job:\n",
    "data_frame['job'].loc[data_frame['job'].str.contains('\\.',na=True)]=data_frame['job'].str.slice(0,-1)\n",
    "data_frame['job']=data_frame['job'].str.replace(r'\\W',\"\")\n",
    "\n",
    "\n",
    "#For Marital:\n",
    "data_frame['marital'] = data_frame['marital'].replace(['div','Div'],'divorced')\n",
    "data_frame['marital'] = data_frame['marital'].replace(['M',\"Married\",\"maried\",\"mairied\",\"marirred\"],'married')\n",
    "data_frame['marital'] = data_frame['marital'].replace(\"Single\",'single')\n",
    "data_frame = data_frame[data_frame['marital']!='1']\n",
    "\n",
    "#For day\n",
    "data_frame=data_frame[data_frame['day'].str.len()<=2]\n",
    "\n",
    "#For Month\n",
    "data_frame['month'] = data_frame['month'].replace(['August','august'],'aug')\n",
    "data_frame=data_frame[~data_frame['month'].isin(['27-Aug','8-Aug'])]\n",
    "\n",
    "#For Duration:\n",
    "data_frame['duration'][data_frame['duration']<0]=0\n",
    "data_frame['duration'][data_frame['duration'].isnull()]=data_frame['duration'].mean()\n",
    "\n",
    "\n",
    "#For Balance\n",
    "data_frame['balance'][data_frame['balance']<0]=0\n",
    "\n",
    "#For Campaign:\n",
    "#As there is only one record with out any campain number it can be avoided \n",
    "data_frame=data_frame[~data_frame[\"campaign\"].isnull()]\n",
    "\n",
    "\n",
    "#For poutcome:\n",
    "mode=data_frame['poutcome'].mode()\n",
    "data_frame['poutcome'].fillna(mode[0],inplace=True)\n",
    "\n",
    "#For pdays\n",
    "mode=data_frame['pdays'].mode()\n",
    "data_frame['pdays'].fillna(mode[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh9UM5hqn1HO"
   },
   "source": [
    "[LP 2] Use encoders and convert the categorical variables to numerical values.\n",
    "\n",
    "[HP 1] Describe your choice of encoder for these columns and explain why they are appropriate for the column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "8S41K2hfCWPa"
   },
   "outputs": [],
   "source": [
    "## Your code for LP 2 goes here. \n",
    "\n",
    "#Encoding Job Column\n",
    "data_frame=data_frame[data_frame['job'].notna()]\n",
    "data_frame=data_frame[data_frame['job']!='unknown']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder2 = LabelEncoder()\n",
    "data_frame['ENCODED_JOB'] = encoder2.fit_transform(data_frame['job'])\n",
    "\n",
    "#Encoding marital column:\n",
    "data_frame['ENCODED_MARITAL'] = encoder2.fit_transform(data_frame['marital'])\n",
    "\n",
    "#Encoded education column:\n",
    "data_frame=data_frame[data_frame['education'].notna()]\n",
    "Educational_dict = {'primary' : 1,'secondary' : 2,'tertiary' :3}\n",
    "data_frame['ENCODED_EDUCATION'] = data_frame['education'].map(Educational_dict)\n",
    "\n",
    "#Encoding default column:\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder1 = LabelBinarizer()\n",
    "data_frame['ENCODED_DEFAULT']=encoder1.fit_transform(data_frame['default'].values.reshape(-1,1))\n",
    "\n",
    "#Encoding housing column:\n",
    "data_frame['ENCODED_HOUSING']=encoder1.fit_transform(data_frame['housing'].values.reshape(-1,1))\n",
    "\n",
    "#Encoding Contact column:\n",
    "data_frame['ENCODED_CONTACT'] = encoder2.fit_transform(data_frame['contact'])\n",
    "\n",
    "#Encoding P_outcome\n",
    "data_frame['ENCODED_POUTCOME'] = encoder2.fit_transform(data_frame['poutcome'])\n",
    "\n",
    "#Encodin months\n",
    "months_dict = {'jan' : 1,'feb' : 2,'mar' :3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12}\n",
    "data_frame['ENCODED_MONTHS'] = data_frame['month'].map(months_dict)\n",
    "\n",
    "#Encoding Loan:\n",
    "data_frame['ENCODED_LOAN']=encoder1.fit_transform(data_frame['loan'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "#Encodin y\n",
    "data_frame['ENCODED_Y']=encoder1.fit_transform(data_frame['y'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4cohM7LCXy7"
   },
   "source": [
    "< Your answer for HP 1 goes here >\n",
    "\n",
    "1) Column 'Job':\n",
    "Encoder Used : LabelEncode\n",
    "Reason: In the given column there are 11 unique values, for all these values 11 unique numbers are assigned and because of this relation among them is not violated.\n",
    "\n",
    "2) Colum marital:\n",
    "Encoder Used : LabelEncode\n",
    "Reason: In the given column there are 3 unique values, for all these values 3 unique numbers are assigned and because of this relation among them is not violated.\n",
    "\n",
    "3) Education column:\n",
    "This column has three different field 'primary','secondary','tertiary' for all these value based on their level concurent ranking is given so that ordinal meaning is not currupted.\n",
    "\n",
    "4) Default Column:\n",
    "Encoder:LabelBinarizer\n",
    "This column containd only two vales, yes and no. If we use any binary encoding technique like LabelBinarizer we can generate binary values which satisfies or requiremnt.\n",
    "\n",
    "5) Housing Column:\n",
    "Encoder:LabelBinarizer\n",
    "This column containd only two vales, yes and no. If we use any binary encoding technique like LabelBinarizer we can generate binary values which satisfies or requiremnt.\n",
    "\n",
    "6) Encoded Contact:\n",
    "Encoder: LabelEncode\n",
    "Reason: In the given column there are 3 unique values, for all these values 3 unique numbers are assigned and because of this relation among them is not violated.\n",
    "\n",
    "7) Encoded Poutcome:\n",
    "Encoder: LabelEncode\n",
    "Reason: In the given column there are 3 unique values, for all these values 3 unique numbers are assigned and because of this relation among them is not violated.\n",
    "\n",
    "8) Encoded month:\n",
    "Starting from 1 every month is given its corresponding integer value.\n",
    "\n",
    "9) Encoding Y:\n",
    "LabelBinarizer\n",
    "This column containd only two vales, yes and no. If we use any binary encoding technique like LabelBinarizer we can generate binary values which satisfies or requiremnt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYIkt1kNn4AQ"
   },
   "source": [
    "[LP 3] Use an appropriate scaler to scale the numerical values to a suitable range of values. Briefly explain the process you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "GNhdECajCdZK"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OLD COMMANDS\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler(feature_range=(5, 10))\n",
    "data_frame[['age','balance','day','duration','ENCODED_JOB','ENCODED_MARITAL','ENCODED_EDUCATION','ENCODED_DEFAULT','ENCODED_HOUSING','ENCODED_CONTACT','ENCODED_POUTCOME','ENCODED_MONTHS','ENCODED_Y']]=min_max.fit_transform(data_frame[['age','balance','day','duration','ENCODED_JOB','ENCODED_MARITAL','ENCODED_EDUCATION','ENCODED_DEFAULT','ENCODED_HOUSING','ENCODED_CONTACT','ENCODED_POUTCOME','ENCODED_MONTHS','ENCODED_Y']])\n",
    "\"\"\"\n",
    "#New Commands\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler(feature_range=(-1, 15))\n",
    "\n",
    "#\"AGE\": Min_Max scalling\n",
    "#Reason: From the data we can see that the age is of fixed range and doesn't have much outliners so min_max scalling would be a good option\n",
    "data_frame[\"SCALLED_AGE\"]=min_max.fit_transform(data_frame[['age']])\n",
    "\n",
    "#JOB column:No Scalling required\n",
    "#Reason: As the column ENCODED_JOB consists encoded values for distinc jobs in range 0 to 15 there is no need of scalling.\n",
    "\n",
    "#Martical:No Scalling required\n",
    "#Reason: As ENCODED_MARTIAL column consists of only 3 distinct numeric values 0,1,2 (which are in range 0-15) there is no need of scalling.\n",
    "\n",
    "#Education: No Scalling required\n",
    "#Reason: As ENCODED_EDUCATION column consists of only 3 distinct numeric values 1,2,3 (which are in range 0-15) there is no need of scalling.\n",
    "\n",
    "#Default: No Scalling required\n",
    "#Reason: As ENCODED_DEFAULT column consists of only 2 distinct numeric values 0,1 (which are in range 0-15) there is no need of scalling.\n",
    "\n",
    "#Balance: Standard Scaler\n",
    "#Reason: As the balance is dynamic and there is no particular range for it Standard Scaler(z-score normalization) would be more fit.\n",
    "data_frame['balance']=data_frame['balance'].astype('float64')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Scaler=StandardScaler()\n",
    "normal=Scaler.fit_transform(data_frame[['balance']])\n",
    "normal=[x[0] for x in normal]\n",
    "data_frame['SCALED_BALANCE']=normal\n",
    "\n",
    "#Housing: No need of scalling\n",
    "#Reason:As ENCODED_HOUSING column consists of only 2 distinct numeric values 0,1, which are in range (-1 -15) there is no need of scalling.\n",
    "\n",
    "#Loan: No need of scalling\n",
    "#Reason:As ENCODED_LOAN column consists of only 2 distinct numeric values 0,1, which are in range (-1 -15) there is no need of scalling.\n",
    " \n",
    "#Contact: No need of scalling\n",
    "#Reason: As ENCODED_CONTACT column consists of only 3 distinct numeric values 0,1,2, which are in range (-1 -15) there is no need of scalling.\n",
    " \n",
    "#DAY: MIN_MAX scalling\n",
    "#Reason: As day number will be in fixed range from (1 to 31), we can scale day column to range (-1 -15)\n",
    "data_frame[\"SCALLED_DAY\"]=min_max.fit_transform(data_frame[['day']])\n",
    "\n",
    "#Month: No scalling required\n",
    "#Reason: As the ENCODED_MONTHS in range (1 -12) which is in range (-1 -15) there is no need of scalling\n",
    "\n",
    "#Duration:Standard Scaler\n",
    "#Reason: As the Duration is dynamic and there is no particular range for it Standard Scaler(z-score normalization) would be more fit.\n",
    "temp=Scaler.fit_transform(data_frame[['duration']])\n",
    "temp=[x[0] for x in temp]\n",
    "data_frame['SCALED_DURATION']=temp\n",
    "\n",
    "\n",
    "#Campaign: Standard Scaler\n",
    "#Reason: As the Campaign is dynamic and there is no particular range for it Standard Scaler(z-score normalization) would be more fit.\n",
    "temp=Scaler.fit_transform(data_frame[['campaign']])\n",
    "temp=[x[0] for x in temp]\n",
    "data_frame['SCALED_CAMPAIGN']=temp\n",
    "\n",
    "\n",
    "#pdays: Standard Scaler\n",
    "#Reason: As the pdays is dynamic and there is no particular range for it Standard Scaler(z-score normalization) would be more fit.\n",
    "temp=Scaler.fit_transform(data_frame[['pdays']])\n",
    "temp=[x[0] for x in temp]\n",
    "data_frame['SCALED_PDAYS']=temp\n",
    "\n",
    "#previous: min_max scaler\n",
    "#Reason: As the given pdays fall in a small range(0-23) we can apply min_max scalling on this column\n",
    "data_frame[\"SCALLED_PREVIOUS\"]=min_max.fit_transform(data_frame[['previous']])\n",
    "\n",
    "\n",
    "#poutcome: No scalling required\n",
    "# Reason: As the ENCODED_POUTCOME in range (1 -2) which is in range (-1 -15) there is no need of scalling\n",
    "\n",
    "\n",
    "#y: No Scalling required\n",
    "#Reason: As ENCODED_Y have only 2 unique values (0,1) which are in desired range no need of scalling\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2119\n",
       "Name: pdays, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['pdays'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWT5NohBoJjV"
   },
   "source": [
    "Save your clean dataset in a file called **bank_clean.csv**. Submit this file along with the ipynb solution file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "rBCXHZRLCgJq"
   },
   "outputs": [],
   "source": [
    "## Your code to save the dataframe to a csv file goes here. \n",
    "data_frame.to_csv(\"Bank_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9BYddxxAv9K"
   },
   "source": [
    "[HP 2] After cleaning the data, are there any columns that seem redundant or unnecessary? If there is a particular business outcome for which a column might be unnecessary, please state it here.\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yic6PaOCkfL"
   },
   "source": [
    "< Your answer for HP 2 goes here >\n",
    "1) Contact: Contact communication type, this attribute doesn't hold any logic significance in building the model or any prediction.\n",
    "\n",
    "2)Education:The type of the degree our customer hold will have less significane in building a model.\n",
    "\n",
    "3) Day: We already have duration colum through which can identify the numnber of days so this column might not have much significance.\n",
    "\n",
    "4) Month: As we have duration column through which we can identify the last contacted month, this column will have less significane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54AMLMvoBLb7"
   },
   "source": [
    "[HP 3] What is the average duration of calls made in the month of November? Plot a histogram of call duration in the month of November."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "287.8238636363636"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code for HP 3 goes here. \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "OLD COMMANDS\n",
    "x = data_frame['duration'][data_frame['month']=='aug']\n",
    "\n",
    "plt.hist(x)\n",
    "plt.show() \"\"\"\n",
    "\n",
    "#NEW COMMANDS\n",
    "bank_data=pd.read_csv(\"bank-hw1.csv\")\n",
    "duration=bank_data[bank_data['month']=='nov']['duration']\n",
    "\n",
    "\n",
    "plt.hist(duration)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "duration.mean() #Average duration of calls made in the month of November is 287.8238636363636"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3l1ztNR5BbPa"
   },
   "source": [
    "[HP 4] How many times on an average were customers whose \"poutcome\" was \"success\" contacted previously (\"previous\" column contains this information)? How does this compare to the customers whose \"poutcome\" was \"failure\" or \"other\"? What insight does this step provide?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "49nC0392n5cG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code for HP 4 goes here. \n",
    "##customers with pout ='success' and previous >0\n",
    "\n",
    "success_data=data_frame['previous'][(data_frame['poutcome']=='success') & data_frame['previous']>0]\n",
    "\n",
    "#round(success_data.mean()) #Average time customer was contacted was 3\n",
    "\n",
    "round(data_frame['previous'][(data_frame['poutcome']=='unknown') & data_frame['previous']>0].mean()) #7\n",
    "\n",
    "#Insights:\n",
    "#1)On an average customers were contacted 3 times previously for whom the poutcome is success.\n",
    "\n",
    "#2) On an average customers were contacted 3 times previously for whom the poutcome is Failure.\n",
    "\n",
    "#3) For the customers whose outcome is \"unknown\" they were contacted 7 times previously.\n",
    "\n",
    "#4) From this insights we can observe that the customer's whose poutcome is succees or failure were contacted 3 time on an average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQYb_dd3obyT"
   },
   "source": [
    "# References\n",
    "https://matplotlib.org/3.5.1/api/_as_gen/matplotlib.pyplot.hist.html\n",
    "\n",
    "Note: I had few discussions with one of my classmate Sai Varshith Talluri[SSID:015952586].\n",
    "\n",
    "# What to turn in:\n",
    "1. The ipynb solution file, which includes the references\n",
    "2. If you use Colab or GitHub for version control, please share a link to your notebook or GitHub repository\n",
    "3. The bank_clean.csv file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW1 Part 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
